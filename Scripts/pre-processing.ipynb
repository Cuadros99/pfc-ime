{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import PowerTransformer, MinMaxScaler\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None, 'display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir_path = './../Datasets/CSE-CIC-IDS2018/raw/original/'\n",
    "files_name_list = os.listdir(dataset_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_list = []\n",
    "for file_name in files_name_list:\n",
    "    file_path = os.path.join(dataset_dir_path, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_dataset_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat(df_dataset_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_pattern = './../Datasets/CSE-CIC-IDS2018/raw/original/02-14-2018.csv'\n",
    "# dataset = pd.read_csv(file_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Benign            667626\n",
       "FTP-BruteForce    193360\n",
       "SSH-Bruteforce    187589\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_functions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redimensionamento da coluna Alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes = dataset[\"Label\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso as classes não estejam separadas em 0 (Benígno) e 1 (Malígno) é feito esse redimensionamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = target_classes.keys()\n",
    "\n",
    "if not (0 in classes and 1 in classes and len(classes) == 2):\n",
    "    for target in target_classes:\n",
    "        value = 0 if target == \"Benign\"else 1\n",
    "        dataset.replace(to_replace=target, value=value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    667626\n",
       "1    380949\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = dataset.columns.values\n",
    "columns = np.delete(columns, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de dados ruidosos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset.drop(columns=['Timestamp'], inplace=True)\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.delete(columns, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversão de tipos incorretos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate throught each dataframe in the dictionary\n",
    "for key in dataset.keys():\n",
    "    for col in dataset.columns:\n",
    "        #Check if the datatype of the column is object\n",
    "        if dataset[col].dtype == 'object' and col != 'Label':\n",
    "            # Change all values to numeric, and to NaN if it is a strig\n",
    "            dataset[col] = pd.to_numeric(dataset[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particionamento estratificado dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = train_test_split(dataset, test_size=0.3, stratify=dataset['Label'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset_train.drop(columns=['Label'])\n",
    "Y_train = dataset_train['Label']\n",
    "\n",
    "X_test = dataset_test.drop(columns=['Label'])\n",
    "Y_test = dataset_test['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substituição de dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a imputação nos dados de treino\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_functions['inputer'] = imputer.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação Yeo-Johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = PowerTransformer(method='yeo-johnson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste e transformação nos dados de treino\n",
    "X_train_transformed = transformer.fit_transform(X_train_imputed)\n",
    "\n",
    "# Transformação nos dados de teste\n",
    "X_test_transformed = transformer.transform(X_test_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_functions['transformer'] = transformer.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste e transformação nos dados de treino\n",
    "X_train_normalized = scaler.fit_transform(X_train_transformed)\n",
    "\n",
    "# Transformação nos dados de teste\n",
    "X_test_normalized = scaler.transform(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_functions['scaler'] = scaler.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilizador/pfc/venv/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Criação do modelo Elliptic Envelope\n",
    "ee = EllipticEnvelope(contamination=0.01) \n",
    "\n",
    "# Ajuste do modelo aos dados de treino normalizados\n",
    "ee.fit(X_train_normalized)\n",
    "\n",
    "# Identificar os outliers nos dados de treino\n",
    "y_pred_train = ee.predict(X_train_normalized)\n",
    "\n",
    "# Remover os outliers dos dados de treino\n",
    "X_train_no_outliers = X_train_normalized[y_pred_train == 1]\n",
    "Y_train_no_outliers = Y_train[y_pred_train == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de multicolinearidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class RemoveMulticollinearity:    \n",
    "    def __init__(self, threshold=0.9):  # Ajuste o threshold conforme necessário\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Convert arrays to DataFrame for correlation computation\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        if y is not None and isinstance(y, np.ndarray):\n",
    "            y = pd.Series(y)\n",
    "\n",
    "        if y is None:\n",
    "            corr_X = X.corr()\n",
    "        else:\n",
    "            data = X.copy()\n",
    "            data['Label'] = y\n",
    "            corr_matrix = data.corr()\n",
    "            corr_X, corr_y = corr_matrix.iloc[:-1, :-1], corr_matrix.iloc[:-1, -1]\n",
    "\n",
    "        self.drop_ = set()\n",
    "        for col in corr_X.columns:\n",
    "            # Select columns that are correlated above the threshold\n",
    "            corr = corr_X[col][corr_X[col] >= self.threshold]\n",
    "\n",
    "            # Always finds itself with correlation 1\n",
    "            if len(corr) > 1:\n",
    "                if y is None:\n",
    "                    # Drop all but the first one\n",
    "                    self.drop_.update(list(corr.index[1:]))\n",
    "                else:\n",
    "                    # Keep feature with the highest correlation with y\n",
    "                    keep = corr_y[corr.index].idxmax()\n",
    "                    self.drop_.update(list(corr.index.drop(keep)))\n",
    "\n",
    "        self.drop_ = list(self.drop_)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Convert arrays to DataFrame for dropping columns\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        return X.drop(columns=self.drop_, errors='ignore').values\n",
    "\n",
    "    def filter_column_names(self, columns):\n",
    "        columns_filtered = np.delete(columns, self.drop_)\n",
    "        return columns_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar ao conjunto de treino\n",
    "remove_multicollinearity = RemoveMulticollinearity(threshold=0.9)\n",
    "remove_multicollinearity.fit(X_train_no_outliers, Y_train_no_outliers)\n",
    "X_train_no_multicollinearity = remove_multicollinearity.transform(X_train_no_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_filtered = remove_multicollinearity.filter_column_names(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_functions['remove_multicolinearity'] = remove_multicollinearity.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_functions['filter_column_names'] = remove_multicollinearity.filter_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceamento de Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar o SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Aplicar o SMOTE aos dados de treino\n",
    "X_train_balanced, Y_train_balanced = smote.fit_resample(X_train_no_multicollinearity, Y_train_no_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar dataset pre-processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_datetime = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "dataset_treated_dir_path = f'./../Datasets/CSE-CIC-IDS2018/pre-processed/{current_datetime}'\n",
    "os.makedirs(dataset_treated_dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_filtered = np.delete(columns_filtered, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(X_train_balanced, columns=columns_filtered)\n",
    "df_train['Label'] = Y_train_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = f'train_dataset_treated.csv'\n",
    "train_file_path = os.path.join(dataset_treated_dir_path, train_filename)\n",
    "\n",
    "df_train.to_parquet(train_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_no_multicollinearity = remove_multicollinearity.transform(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(X_test_no_multicollinearity, columns=columns_filtered)\n",
    "df_test['Label'] = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filename = f'test_dataset_treated.csv'\n",
    "test_file_path = os.path.join(dataset_treated_dir_path, test_filename)\n",
    "\n",
    "df_test.to_parquet(test_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar funções geradas pelo pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_functions_file_path = os.path.join(dataset_treated_dir_path,'pre_processing_functions.pkl')\n",
    "\n",
    "with open(dict_functions_file_path, 'wb') as file:\n",
    "    pickle.dump(treatment_functions, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
