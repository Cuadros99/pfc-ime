{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.datasets import get_data\n",
    "from pycaret.classification import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None, 'display.max_columns', None)\n",
    "\n",
    "dir_path = os.path.join('..', 'Datasets', 'CSE-CIC-IDS2018', 'pre-processed')\n",
    "\n",
    "# Define the path to the folder containing the CSV files\n",
    "train_file_path = os.path.join(os.getcwd(), dir_path,'train_dataset_treated.parquet')\n",
    "test_file_path = os.path.join(os.getcwd(), dir_path, 'test_dataset_treated.parquet')\n",
    "# Import csv to pandas\n",
    "train_dataset = pd.read_parquet(train_file_path)\n",
    "test_dataset = pd.read_parquet(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8399452"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "setup = setup(\n",
    "    train_dataset, \n",
    "    target = 'Label',\n",
    "    test_data = test_dataset,\n",
    "    preprocess=False,\n",
    "    fold_strategy = 'stratifiedkfold',\n",
    "    fold = 10,\n",
    "    index=False,\n",
    "    n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc, fbeta_score, confusion_matrix\n",
    "\n",
    "def pr_auc(y_true, y_pred, **kwargs):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    return auc(recall, precision)\n",
    "\n",
    "def fbeta(y_true, y_pred, beta=1, **kwargs):\n",
    "    return fbeta_score(y_true, y_pred, beta=beta)\n",
    "\n",
    "\n",
    "def fpr(y_true, y_pred, **kwargs):\n",
    "    # Calcula a matriz de confusão\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    # Calcula o FPR\n",
    "    return fp / (fp + tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.add_metric('f2', 'F2', fbeta, greater_is_better=True, beta=2)\n",
    "setup.add_metric('pr_auc', 'PR-AUC', pr_auc, greater_is_better=True)\n",
    "setup.add_metric('fpr', 'FPR', fpr, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = compare_models(exclude = ['catboost', 'knn'], n_select = 5, sort = 'F2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'setup' (ClassificationExperiment)\n"
     ]
    }
   ],
   "source": [
    "%store setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_comparison_B = pull().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F2</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>0.9635</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.9381</td>\n",
       "      <td>0.9382</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.9780</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>18.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.9661</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>0.9661</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>58.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>0.9863</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.9303</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.9799</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>374.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.9538</td>\n",
       "      <td>0.9794</td>\n",
       "      <td>0.9374</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.9075</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>77.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>0.9326</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>0.8879</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9602</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>17.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "      <td>0.9117</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.8234</td>\n",
       "      <td>0.8260</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>4.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qda</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.8915</td>\n",
       "      <td>0.9498</td>\n",
       "      <td>0.9263</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.7829</td>\n",
       "      <td>0.7849</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.9147</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>8.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.8881</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.8565</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.8845</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.8845</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.0803</td>\n",
       "      <td>2.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>0.8594</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.8830</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>0.7735</td>\n",
       "      <td>0.8830</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>5.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.8137</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.7870</td>\n",
       "      <td>0.8219</td>\n",
       "      <td>0.6273</td>\n",
       "      <td>0.6301</td>\n",
       "      <td>0.8219</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>2.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>Dummy Classifier</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>2.226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
       "dt               Decision Tree Classifier    0.9690  0.9740  0.9635  0.9743   \n",
       "lightgbm  Light Gradient Boosting Machine    0.9669  0.9919  0.9438  0.9895   \n",
       "gbc          Gradient Boosting Classifier    0.9651  0.9863  0.9400  0.9898   \n",
       "ada                  Ada Boost Classifier    0.9538  0.9794  0.9374  0.9691   \n",
       "lr                    Logistic Regression    0.9438  0.9620  0.9326  0.9540   \n",
       "svm                   SVM - Linear Kernel    0.9117  0.9560  0.8725  0.9468   \n",
       "qda       Quadratic Discriminant Analysis    0.8915  0.9498  0.9263  0.8662   \n",
       "ridge                    Ridge Classifier    0.8881  0.9522  0.8565  0.9143   \n",
       "lda          Linear Discriminant Analysis    0.8862  0.9479  0.8594  0.9081   \n",
       "nb                            Naive Bayes    0.8137  0.8980  0.8602  0.7870   \n",
       "dummy                    Dummy Classifier    0.5000  0.5000  0.4000  0.2000   \n",
       "\n",
       "              F1   Kappa     MCC      F2  PR-AUC     FPR  TT (Sec)  \n",
       "dt        0.9688  0.9381  0.9382  0.9688  0.9780  0.0254    18.750  \n",
       "lightgbm  0.9661  0.9337  0.9347  0.9661  0.9807  0.0100    58.133  \n",
       "gbc       0.9642  0.9303  0.9315  0.9642  0.9799  0.0097   374.776  \n",
       "ada       0.9530  0.9075  0.9080  0.9530  0.9689  0.0299    77.964  \n",
       "lr        0.9432  0.8876  0.8879  0.9432  0.9602  0.0449    17.500  \n",
       "svm       0.9081  0.8234  0.8260  0.9081  0.9415  0.0490     4.593  \n",
       "qda       0.8952  0.7829  0.7849  0.8952  0.9147  0.1434     8.778  \n",
       "ridge     0.8845  0.7762  0.7778  0.8845  0.9213  0.0803     2.360  \n",
       "lda       0.8830  0.7724  0.7735  0.8830  0.9189  0.0870     5.125  \n",
       "nb        0.8219  0.6273  0.6301  0.8219  0.8585  0.2329     2.616  \n",
       "dummy     0.2667  0.0000  0.0000  0.2667  0.7500  0.4000     2.226  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_comparison_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = [\"dt\", 'lgbm', 'gradient_boosting', 'ada_boost', 'logistic_regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n",
      "Transformation Pipeline and Model Successfully Saved\n",
      "Transformation Pipeline and Model Successfully Saved\n",
      "Transformation Pipeline and Model Successfully Saved\n",
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    }
   ],
   "source": [
    "# Salvar cada modelo individualmente\n",
    "for i, model in enumerate(best_models):\n",
    "    save_model(model, f'{names_list[i]}_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to save the dataset pre-processed\n",
    "file_path = os.path.join(os.getcwd(), '..', 'Scripts', 'models_comparison', 'pycaret-models-comparison.csv')\n",
    "\n",
    "# Save the dataset pre-processed\n",
    "df_models_comparison_B.to_csv(file_path ,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = best_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tune_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dt_model_tuned \u001b[38;5;241m=\u001b[39m \u001b[43mtune_model\u001b[49m(dt_model, optimize \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tune_model' is not defined"
     ]
    }
   ],
   "source": [
    "dt_model_tuned = tune_model(dt_model, optimize = 'F2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo do Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = df_models_comparison_B.copy()\n",
    "\n",
    "df['Score'] = df.apply(lambda row: 0.1*row['Recall'] + 0.1*row['Prec.'] + 0.2*(1-row['FPR']) + 0.3*row['F2'] + 0.3*row['PR-AUC'], axis=1)\n",
    "df = df[['Prec.','Recall', 'FPR', 'PR-AUC', 'F2', 'Score']]\n",
    "\n",
    "def compute_score(fbeta, pr_auc, fpr, recall, precision):\n",
    "    return 0.3*fbeta + 0.3*pr_auc + 0.2*(1-fpr) + 0.1*recall + 0.1*precision\n",
    "\n",
    "\n",
    "def evaluate_algorithms(df):\n",
    "    df.rename(columns={'Prec.': 'Precision'}, inplace=True)\n",
    "    df['Score'] = df.apply(\n",
    "        lambda row: compute_score(\n",
    "            row['F2'],\n",
    "            row['PR-AUC'],\n",
    "            row['FPR'],\n",
    "            row['Recall'],\n",
    "            row['Precision']\n",
    "        ),\n",
    "        axis = 1 \n",
    "    )\n",
    "\n",
    "    df = df[['Model', 'Precision', 'Recall', 'FPR', 'PR-AUC', 'F2', 'Score']]\n",
    "\n",
    "    return df.copy()\n",
    "\n",
    "df_results_B = evaluate_algorithms(df_models_comparison_B)\n",
    "df_results_B = df_results_B.sort_values(by=['Score'], ascending=False)\n",
    "df_final = df_results_B.copy()\n",
    "# Define the path to save the dataset pre-processed\n",
    "file_path = os.path.join(os.getcwd(), '..', 'Scripts', 'models_comparison', 'pycaret-models-comparison.csv')\n",
    "\n",
    "# Save the dataset pre-processed\n",
    "df_final.to_csv(file_path ,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
